# 1週間MVP実装計画 v0.1

## 方針
- Next.js + PWA（モバイル優先）。音声は 1–2 秒チャンクで処理。
- STTは Groq whisper-large-v3 を優先し、失敗/枯渇時は OpenAI Whisper へフォールバック。
- ローカル保存（IndexedDB）、設定（APIキー/送信ON-OFF）は端末のみ。

## タスクとマイルストーン

Day 1: プロジェクト基盤/録音
- Next.jsプロジェクト/PWA設定、基本UI（録音開始/停止/要約/翻訳/出力）。
- `getUserMedia` でマイク録音、PCは `getDisplayMedia({ audio: true })` のタブ音声も試験実装。
- 音声チャンク化（1–2秒、PCM/Opus）、IndexedDB保存レイヤ。
- 設定画面（APIキー、送信ON/OFF、言語、アクセシビリティ基本）。

Day 2: STT統合（Groq優先）
- Groq STT APIクライアント（ストリーミング or 分割アップロード）。
- 初回暫定表示2秒以内のUI更新ループ。失敗時OpenAI Whisperクライアント実装。
- ノイズ抑制（WebRTC AudioProcessing/RNNoise WASMの軽量導入）。

Day 3: 表示/整形/翻訳
- ライブ字幕UI（確定/暫定の二段表示）。
- 句読点付与/フィラ除去の後処理パイプライン。
- 翻訳字幕（目標3秒以内）。

Day 4: 話者分離/編集
- 簡易VAD＋クラスタリングで話者A/B付与。編集で手動修正可能に。
- 編集機能（文字修正、話者名編集、ハイライト、コメント、簡易履歴）。

Day 5: 要約/抽出/辞書
- 要約ボタンで決定事項/論点/次アクション/期限/担当を生成。
- 用語辞書（.md/.pdf）取込→テキスト抽出→用語反映（候補提示/置換）。
- セクション分割/タイムスタンプ/音声ジャンプのON/OFFを設定。

Day 6: 出力/安定化
- Markdownエクスポート。モバイル最適化・アクセシビリティ調整。
- オフライン時の挙動（録音/保存/後処理待ち）確認。
- エラーハンドリング/リトライ/フォールバック動作確認。

Day 7: QA/パフォーマンス
- 実機（PC/スマホ）でのE2E確認。遅延計測＆簡易チューニング。
- 既知制約・今後の課題の整理、受入基準チェックリストで検収。

## 受入チェックリスト（抜粋）
- 初回暫定字幕が2秒以内に表示される。
- 翻訳字幕が3秒以内で表示される。
- 既存ファイル取り込み→全文文字起こしが完了する。
- 要約に決定事項/論点/次アクション/期限/担当が含まれる。
- 話者A/Bの編集が可能、フィラ除去が有効。
- Markdownでダウンロードできる。ローカル保存のみ。
